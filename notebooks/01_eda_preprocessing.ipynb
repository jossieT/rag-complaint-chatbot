{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27089668",
   "metadata": {},
   "source": [
    "# Task 1: Exploratory Data Analysis & Data Preprocessing\n",
    "This notebook contains the exploratory data analysis and initial preprocessing for the CFPB complaint dataset.\n",
    "\n",
    "## Objectives:\n",
    "1. Load the dataset.\n",
    "2. Perform EDA (Product distribution, narrative length, missingness).\n",
    "3. Filter by target products.\n",
    "4. Clean the complaint narratives.\n",
    "5. Save the processed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd153aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Functions imported and paths defined.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from preprocessing import clean_narrative, filter_complaints, process_dataset\n",
    "from eda_utils import perform_eda\n",
    "\n",
    "# Define paths for the entire notebook\n",
    "raw_data_path = '../data/raw/complaints.csv'\n",
    "output_path = '../data/processed/filtered_complaints.csv'\n",
    "\n",
    "print(\"Setup complete. Functions imported and paths defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a36ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample for interactive EDA to save memory\n",
    "print(f\"Loading 20,000 row sample from {raw_data_path}...\")\n",
    "df_sample = pd.read_csv(raw_data_path, nrows=20000)\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47c1e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform EDA on the sample\n",
    "df_with_narratives = perform_eda(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb78a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing full dataset in chunks (Filtering + Cleaning)...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Full Processing (using chunking for 6GB file)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing full dataset in chunks (Filtering + Cleaning)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/processed\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      4\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/processed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m processed_count \u001b[38;5;241m=\u001b[39m process_dataset(raw_data_path, output_path, chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Full Processing (using chunking for 6GB file)\n",
    "print(\"Processing full dataset in chunks (Filtering + Cleaning)...\")\n",
    "if not os.path.exists('../data/processed'):\n",
    "    os.makedirs('../data/processed')\n",
    "\n",
    "processed_count = process_dataset(raw_data_path, output_path, chunk_size=100000)\n",
    "\n",
    "print(f\"\\nFull processing complete. {processed_count} relevant complaints saved to {output_path}.\")\n",
    "\n",
    "print(\"\\n--- Sample of Processed Data ---\")\n",
    "df_processed_sample = pd.read_csv(output_path, nrows=5)\n",
    "df_processed_sample[['Product', 'Consumer complaint narrative', 'cleaned_narrative']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification of output file\n",
    "if os.path.exists(output_path):\n",
    "    file_size = os.path.getsize(output_path) / (1024 * 1024)\n",
    "    print(f\"Processed file size: {file_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb082fb8",
   "metadata": {},
   "source": [
    "## Insights Summary\n",
    "- **Product Distribution**: ...\n",
    "- **Narrative Length**: ...\n",
    "- **Missing Data**: ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
